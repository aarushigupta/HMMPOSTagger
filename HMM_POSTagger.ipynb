{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aarushigupta/Documents/USC_Spring18/NLP/CodingAssignment1/coding1-data-corpus/zh_train_tagged.txt\n"
     ]
    }
   ],
   "source": [
    "filename = \"zh_train_tagged.txt\"\n",
    "datadir = os.path.join(os.getcwd(), 'coding1-data-corpus', filename)\n",
    "print datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"''\", '(', ')', ',', '.', '...', ':', 'ADD', 'AS', 'BB', 'CC', 'CD', 'DEC', 'DEV', 'DT', 'EC', 'FW', 'HYPH', 'IN', 'JJ', 'LS', 'MD', 'NN', 'NNB', 'NNP', 'PFA', 'PFN', 'PRD', 'PRP', 'RB', 'SFA', 'SFN', 'SFV', 'SLASH', 'UH', 'VC', 'VERB', 'VV', 'WP', 'XX', '``']\n"
     ]
    }
   ],
   "source": [
    "fileOpen = open(datadir,\"r\")\n",
    "fileData = fileOpen.readlines()\n",
    "totalWordOccurences = {}\n",
    "totalTagOccurences = {}\n",
    "for line in fileData:\n",
    "    wordTagPair = line.strip(\"\\n\").split(\" \")\n",
    "    for ele in wordTagPair:\n",
    "        tag = ele.split(\"/\")[-1]\n",
    "        wordList = ele.split(\"/\")[:-1]\n",
    "        word = '/'.join(wordList)\n",
    "\n",
    "        try:\n",
    "            totalWordOccurences[word] += 1\n",
    "        except KeyError as e:\n",
    "            totalWordOccurences[word] = 1\n",
    "        \n",
    "        try:\n",
    "            totalTagOccurences[tag] += 1\n",
    "        except KeyError as e:\n",
    "            totalTagOccurences[tag] = 1\n",
    "\n",
    "\n",
    "uniqueTags = totalTagOccurences.keys()\n",
    "uniqueTags.sort()\n",
    "\n",
    "print uniqueTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VV': 38, 'BB': 10, 'FW': 17, 'DEV': 14, 'NNB': 24, \"''\": 1, 'JJ': 20, 'WP': 39, 'DT': 15, 'DEC': 13, 'PRD': 28, '\"': 0, 'NN': 23, ')': 3, '(': 2, ',': 4, '.': 5, 'LS': 21, 'RB': 30, ':': 7, 'XX': 40, 'HYPH': 18, '...': 6, '``': 41, 'VC': 36, 'CC': 11, 'PRP': 29, 'EC': 16, 'CD': 12, 'AS': 9, 'VERB': 37, 'SLASH': 34, 'IN': 19, 'PFA': 26, 'MD': 22, 'SFV': 33, 'ADD': 8, 'PFN': 27, 'SFN': 32, 'UH': 35, 'NNP': 25, 'SFA': 31}\n"
     ]
    }
   ],
   "source": [
    "tagIndexDict = {}\n",
    "tagIndexDictReverse = {}\n",
    "for tagIndex, tag in enumerate(uniqueTags):\n",
    "    tagIndexDict[tag] = tagIndex\n",
    "    tagIndexDictReverse[tagIndex] = tag\n",
    "print tagIndexDict\n",
    "\n",
    "transitionMatrix = np.ones(shape=(len(uniqueTags), len(uniqueTags)))\n",
    "\n",
    "for line in fileData:\n",
    "    wordTagPairs = line.strip(\"\\n\").split(\" \")\n",
    "    for pairIndex in range(len(wordTagPairs) - 1):\n",
    "        tag1 = wordTagPairs[pairIndex].split(\"/\")[-1]\n",
    "        tag2 = wordTagPairs[pairIndex + 1].split(\"/\")[-1]\n",
    "        tag1Index = tagIndexDict[tag1]\n",
    "        tag2Index = tagIndexDict[tag2]\n",
    "        transitionMatrix[tag1Index][tag2Index] += 1\n",
    "#         if tag1 in tagOccurences:\n",
    "#             tagOccurences[tag1] +=1\n",
    "#         else:\n",
    "#             tagOccurences[tag1] = 1\n",
    "            \n",
    "#     for tag in uniqueTags:\n",
    "#         if tag not in tagOccurences:\n",
    "#             tagOccurences[tag] = 0\n",
    "'''\n",
    "for row in range(len(transitionCounts)):\n",
    "    tag = tagIndexDict.keys()[tagIndexDict.values().index(row)]\n",
    "    countOfTag = float(tagOccurences[tag])\n",
    "    if row == len(transitionCounts) -1:\n",
    "        print \"Last tag: \", tag\n",
    "    for col in range(len(transitionCounts)):\n",
    "        if countOfTag != 0:\n",
    "            transitionMatrix[row][col] = transitionCounts[row][col] / countOfTag\n",
    "        else:\n",
    "            transitionMatrix[row][col] = 0\n",
    "'''\n",
    "transitionMatrix = transitionMatrix / transitionMatrix.sum(axis = 1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  12543\n",
      "{'SLASH': 0.0002475860361475613, 'BB': 0.0022282743253280515, 'FW': 0.006189650903689032, 'DEV': 0.0002475860361475613, ',': 0.0002475860361475613, \"''\": 0.0002475860361475613, 'HYPH': 0.0002475860361475613, 'JJ': 0.01757860856647685, 'WP': 0.0002475860361475613, 'DT': 0.0581827184946769, 'DEC': 0.0002475860361475613, 'PRD': 0.007427581084426839, '\"': 0.0002475860361475613, 'NN': 0.2102005446892795, ')': 0.0002475860361475613, '(': 0.008913097301312206, 'NNB': 0.0004951720722951226, '.': 0.0002475860361475613, 'LS': 0.0009903441445902451, 'RB': 0.06016340678385739, ':': 0.0002475860361475613, 'XX': 0.0002475860361475613, 'PRP': 0.05471651398861104, '...': 0.0002475860361475613, '``': 0.0032186184699182965, 'VC': 0.0004951720722951226, 'CC': 0.0002475860361475613, 'EC': 0.0002475860361475613, 'CD': 0.13518197573656845, 'ADD': 0.0002475860361475613, 'VERB': 0.0002475860361475613, 'VV': 0.06362961128992325, 'IN': 0.12824956672443674, 'PFA': 0.008913097301312206, 'MD': 0.0017331022530329288, 'SFV': 0.0002475860361475613, 'AS': 0.0002475860361475613, 'PFN': 0.0004951720722951226, 'SFN': 0.0002475860361475613, 'UH': 0.0002475860361475613, 'NNP': 0.22555087893042833, 'SFA': 0.0002475860361475613}\n"
     ]
    }
   ],
   "source": [
    "initialProbablities = {}\n",
    "sentenceCount = len(fileData)\n",
    "print \"length: \", fileLength\n",
    "for line in fileData:\n",
    "    wordTagPairs = line.strip(\"\\n\").split(\" \")\n",
    "    tag = wordTagPairs[0].split(\"/\")[-1]\n",
    "    try:\n",
    "        initialProbablities[tag] += 1\n",
    "    except KeyError as e:\n",
    "        initialProbablities[tag] = 1\n",
    "        \n",
    "    \n",
    "        \n",
    "for tag in uniqueTags:\n",
    "    try:\n",
    "        initialProbablities[tag] += 1\n",
    "    except KeyError as e:\n",
    "        initialProbablities[tag] = 1\n",
    "    sentenceCount += 1\n",
    "        \n",
    "initialProbablities.update((tag, (value*1.0/sentenceCount) ) for tag, value in initialProbablities.items())\n",
    "print initialProbablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  12543\n",
      "{'SLASH': 0.0002475860361475613, 'BB': 0.0002475860361475613, 'FW': 0.0002475860361475613, 'DEV': 0.0002475860361475613, ',': 0.0017331022530329288, \"''\": 0.00569447883139391, 'JJ': 0.0002475860361475613, 'WP': 0.0002475860361475613, 'DT': 0.0002475860361475613, 'DEC': 0.0002475860361475613, 'PRD': 0.0002475860361475613, '\"': 0.0002475860361475613, 'NN': 0.0009903441445902451, ')': 0.0014855162168853676, '(': 0.0002475860361475613, 'NNB': 0.0004951720722951226, '.': 0.9764793265659817, 'HYPH': 0.0002475860361475613, 'RB': 0.0002475860361475613, ':': 0.0029710324337707352, 'XX': 0.0002475860361475613, 'LS': 0.0002475860361475613, '...': 0.0007427581084426838, '``': 0.0002475860361475613, 'VC': 0.0002475860361475613, 'CC': 0.0002475860361475613, 'PRP': 0.0002475860361475613, 'EC': 0.0004951720722951226, 'CD': 0.0002475860361475613, 'AS': 0.0002475860361475613, 'VERB': 0.0002475860361475613, 'VV': 0.0007427581084426838, 'IN': 0.0004951720722951226, 'PFA': 0.0002475860361475613, 'MD': 0.0002475860361475613, 'SFV': 0.0002475860361475613, 'ADD': 0.0002475860361475613, 'PFN': 0.0002475860361475613, 'SFN': 0.0002475860361475613, 'UH': 0.0002475860361475613, 'NNP': 0.0002475860361475613, 'SFA': 0.0002475860361475613}\n"
     ]
    }
   ],
   "source": [
    "endProbablities = {}\n",
    "sentenceCount = len(fileData)\n",
    "print \"length: \", fileLength\n",
    "for line in fileData:\n",
    "    lastWordTagPair = line.strip(\"\\n\").split(\" \")[-1]\n",
    "    tag = lastWordTagPair.split(\"/\")[-1]\n",
    "    try:\n",
    "        endProbablities[tag] += 1\n",
    "    except KeyError as e:\n",
    "        endProbablities[tag] = 1\n",
    "        \n",
    "    \n",
    "        \n",
    "for tag in uniqueTags:\n",
    "    try:\n",
    "        endProbablities[tag] += 1\n",
    "    except KeyError as e:\n",
    "        endProbablities[tag] = 1\n",
    "    sentenceCount += 1\n",
    "        \n",
    "endProbablities.update((tag, (value*1.0/sentenceCount) ) for tag, value in endProbablities.items())\n",
    "print endProbablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = totalWordOccurences.keys()\n",
    "uniqueWords.sort()\n",
    "wordIndexDict = {}\n",
    "wordIndexDictReverse = {}\n",
    "for wordIndex, word in enumerate(uniqueWords):\n",
    "    wordIndexDict[word] = wordIndex\n",
    "    wordIndexDictReverse[wordIndex] = word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissionMatrix = np.zeros(shape = (len(uniqueTags), len(uniqueWords)))\n",
    "\n",
    "for line in fileData:\n",
    "    wordTagPairs = line.strip(\"\\n\").split(\" \")\n",
    "    for ele in wordTagPairs:\n",
    "        tag = ele.split(\"/\")[-1]\n",
    "        wordList = ele.split(\"/\")[:-1]\n",
    "        word = '/'.join(wordList)\n",
    "        \n",
    "        tagIndex = tagIndexDict[tag]\n",
    "        wordIndex = wordIndexDict[word]\n",
    "        \n",
    "        emissionMatrix[tagIndex][wordIndex] += 1\n",
    "emissionMatrix = emissionMatrix / emissionMatrix.sum(axis = 1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85.0\n",
      "Accuracy:  85.5\n",
      "Accuracy:  84.3333333333\n",
      "Accuracy:  84.25\n",
      "Accuracy:  85.0\n",
      "Accuracy:  86.0\n",
      "Accuracy:  86.1428571429\n",
      "Accuracy:  86.125\n",
      "Accuracy:  86.1111111111\n",
      "Accuracy:  86.0\n",
      "Accuracy:  86.1818181818\n",
      "Accuracy:  86.75\n",
      "Accuracy:  86.7692307692\n",
      "Accuracy:  86.7142857143\n",
      "Accuracy:  86.3333333333\n",
      "Accuracy:  86.25\n",
      "Accuracy:  86.1764705882\n",
      "Accuracy:  85.8888888889\n",
      "Accuracy:  85.3684210526\n",
      "Accuracy:  85.3\n",
      "Accuracy:  84.9523809524\n",
      "Accuracy:  84.8636363636\n",
      "Accuracy:  84.9565217391\n",
      "Accuracy:  85.2916666667\n",
      "Accuracy:  85.24\n",
      "Accuracy:  85.2307692308\n",
      "Accuracy:  85.3333333333\n",
      "Accuracy:  85.5\n",
      "Accuracy:  85.6896551724\n",
      "Accuracy:  85.5666666667\n",
      "Accuracy:  85.6774193548\n",
      "Accuracy:  85.875\n",
      "Accuracy:  86.1515151515\n",
      "Accuracy:  86.2352941176\n",
      "Accuracy:  86.3714285714\n",
      "Accuracy:  86.3055555556\n",
      "Accuracy:  86.2162162162\n",
      "Accuracy:  86.1578947368\n",
      "Accuracy:  86.0769230769\n",
      "Accuracy:  86.05\n",
      "Accuracy:  86.0975609756\n",
      "Accuracy:  86.3333333333\n",
      "Accuracy:  86.3720930233\n",
      "Accuracy:  86.3181818182\n",
      "Accuracy:  86.4\n",
      "Accuracy:  86.4130434783\n",
      "Accuracy:  86.5744680851\n",
      "Accuracy:  86.5208333333\n",
      "Accuracy:  86.4489795918\n",
      "Accuracy:  86.38\n",
      "Accuracy:  86.0784313725\n",
      "Accuracy:  86.2115384615\n",
      "Accuracy:  86.2830188679\n",
      "Accuracy:  86.3888888889\n",
      "Accuracy:  86.3090909091\n",
      "Accuracy:  86.1964285714\n",
      "Accuracy:  86.2456140351\n",
      "Accuracy:  86.2413793103\n",
      "Accuracy:  86.1186440678\n",
      "Accuracy:  86.1\n",
      "Accuracy:  86.1147540984\n",
      "Accuracy:  86.1774193548\n",
      "Accuracy:  86.2222222222\n",
      "Accuracy:  86.21875\n",
      "Accuracy:  86.1076923077\n",
      "Accuracy:  86.1363636364\n",
      "Accuracy:  86.1940298507\n",
      "Accuracy:  86.1911764706\n",
      "Accuracy:  86.2028985507\n",
      "Accuracy:  86.2571428571\n",
      "Accuracy:  86.1408450704\n",
      "Accuracy:  86.1666666667\n",
      "Accuracy:  86.1643835616\n",
      "Accuracy:  86.1891891892\n",
      "Accuracy:  86.2533333333\n",
      "Accuracy:  86.1052631579\n",
      "Accuracy:  86.1428571429\n",
      "Accuracy:  86.1666666667\n",
      "Accuracy:  86.164556962\n",
      "Accuracy:  86.225\n",
      "Accuracy:  86.2716049383\n",
      "Accuracy:  86.1463414634\n",
      "Accuracy:  86.0240963855\n",
      "Accuracy:  86.0476190476\n",
      "Accuracy:  85.9882352941\n",
      "Accuracy:  85.9651162791\n",
      "Accuracy:  85.9540229885\n",
      "Accuracy:  85.9090909091\n",
      "Accuracy:  85.9775280899\n",
      "Accuracy:  86.0777777778\n",
      "Accuracy:  86.0659340659\n",
      "Accuracy:  86.097826087\n",
      "Accuracy:  86.0967741935\n",
      "Accuracy:  86.0531914894\n",
      "Accuracy:  86.0105263158\n",
      "Accuracy:  85.9479166667\n",
      "Accuracy:  85.9175257732\n",
      "Accuracy:  85.9591836735\n",
      "Accuracy:  85.9595959596\n",
      "Accuracy:  85.96\n",
      "Accuracy:  85.9900990099\n",
      "Accuracy:  86.0196078431\n",
      "Accuracy:  85.9902912621\n",
      "Accuracy:  86.0673076923\n",
      "Accuracy:  86.0285714286\n",
      "Accuracy:  86.0849056604\n",
      "Accuracy:  86.0841121495\n",
      "Accuracy:  86.0092592593\n",
      "Accuracy:  85.9449541284\n",
      "Accuracy:  85.9636363636\n",
      "Accuracy:  86.027027027\n",
      "Accuracy:  86.0625\n",
      "Accuracy:  86.0619469027\n",
      "Accuracy:  86.0526315789\n",
      "Accuracy:  86.052173913\n",
      "Accuracy:  86.0775862069\n",
      "Accuracy:  86.0769230769\n",
      "Accuracy:  86.0677966102\n",
      "Accuracy:  86.0168067227\n",
      "Accuracy:  86.075\n",
      "Accuracy:  86.1074380165\n",
      "Accuracy:  86.1393442623\n",
      "Accuracy:  86.0650406504\n",
      "Accuracy:  86.1209677419\n",
      "Accuracy:  86.144\n",
      "Accuracy:  86.1587301587\n"
     ]
    }
   ],
   "source": [
    "filenameTestTagged = \"zh_dev_tagged.txt\"\n",
    "\n",
    "filenameTestRaw = \"zh_dev_raw.txt\"\n",
    "testdir = os.path.join(os.getcwd(), 'coding1-data-corpus', filenameTestRaw)\n",
    "taggedTestDir = os.path.join(os.getcwd(), 'coding1-data-corpus', filenameTestTagged)\n",
    "fileOpenTest = open(testdir,\"r\")\n",
    "fileOpenTestTagged  = open(taggedTestDir,\"r\")\n",
    "testData = fileOpenTest.readlines()\n",
    "taggedTestData = fileOpenTestTagged.readlines()\n",
    "\n",
    "totalWordCount = 0\n",
    "correctlyTagged = 0\n",
    "\n",
    "for sentenceIndex in range(len(testData)):\n",
    "    words = testData[sentenceIndex].strip(\"\\n\").split(\" \")\n",
    "    #print words\n",
    "    \n",
    "\n",
    "\n",
    "#def viterbi(sentence, uniqueTags,transitionMatrix, emissionMatrix, initialProbablities):\n",
    "#sentence = \"Hiller asked Bush to name the leaders of Chechnya , Taiwan , India and Pakistan .\"\n",
    "#sentence = \"President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area .\"\n",
    "#sentence = \"The sheikh in wheel - chair has been attacked with a F - 16 - launched bomb .\"\n",
    "#     unseenWords = []\n",
    "#     for word in words:\n",
    "#         if word not in uniqueWords:\n",
    "#             unseenWords.append(word)\n",
    "#             uniqueWords.append(word)\n",
    "#             wordIndexDict[word] = uniqueWords.index(word)\n",
    "            \n",
    "        \n",
    "\n",
    "#     for wordIndex in range(len(unseenWords)):\n",
    "#         newcol = np.ones(shape =(len(uniqueTags), 1))\n",
    "#         countOfWordasTag = np.hstack([countOfWordasTag, newcol])\n",
    "\n",
    "#     for wordIndex in range(len(unseenWords)):\n",
    "#         for tagIndex in range(len(uniqueTags)):\n",
    "#             #countOfWordasTag = np.append(countOfWordasTag[tagIndex],1)\n",
    "#             tag = tagIndexDict.keys()[tagIndexDict.values().index(tagIndex)]\n",
    "#             totalTagOccurences[tag] += 1\n",
    "\n",
    "    #countOfWordasTag.reshape((len(uniqueTags), len(uniqueWords)))\n",
    "#     print words\n",
    "#     print unseenWords\n",
    "#     print \"Length of Unique Words: \", len(uniqueWords)        \n",
    "\n",
    "#     if len(unseenWords) > 0:\n",
    "#         emissionMatrix = np.zeros(shape = (len(uniqueTags), len(uniqueWords)))\n",
    "\n",
    "#         for row in range(len(uniqueTags)):\n",
    "#             for col in range(len(uniqueWords)):\n",
    "#                 tag = tagIndexDict.keys()[tagIndexDict.values().index(row)]\n",
    "#                 countOfTag = float(totalTagOccurences[tag])\n",
    "\n",
    "#                 emissionMatrix[row][col] = countOfWordasTag[row][col] / countOfTag\n",
    "\n",
    "#     #print words\n",
    "\n",
    "\n",
    "    viterbiMatrix = np.zeros(shape = (len(uniqueTags), len(words)))\n",
    "    \n",
    "    correspondingTags = [[\"\" for y in range(len(words))]for x in range(len(uniqueTags))]\n",
    "    for col in range(len(words)):\n",
    "        for row in range(len(uniqueTags)):\n",
    "            tag = tagIndexDictReverse[row]\n",
    "            word = words[col]\n",
    "            #check for word not in training data, obsProb = 0\n",
    "            try:\n",
    "                obsProbability = emissionMatrix[row][wordIndexDict[word]]\n",
    "            except KeyError as e:\n",
    "                obsProbability = 1.0\n",
    "                \n",
    "#                 if obsProbability == 0.0:\n",
    "#                     obsProbability = 1.0\n",
    "            #print obsProbability\n",
    "            if col == 0:\n",
    "                transitionProbability = initialProbablities[tag]\n",
    "                #print \"Transition: \", transitionProbability\n",
    "                viterbiMatrix[row][col] = transitionProbability * obsProbability\n",
    "                #print viterbiMatrix[row][col]\n",
    "                correspondingTags[row][col] = tag\n",
    "            else:\n",
    "                for prevColrow in range(len(uniqueTags)):\n",
    "                    prevTag = tagIndexDictReverse[prevColrow]\n",
    "                    transitionProbability = transitionMatrix[prevColrow][row]\n",
    "                    #print transitionProbability\n",
    "                    prevVal = viterbiMatrix[prevColrow][col-1]\n",
    "                    probabilityVal = transitionProbability*obsProbability*prevVal\n",
    "                    #print probabilityVal\n",
    "                    if probabilityVal > viterbiMatrix[row][col]:\n",
    "                        correspondingTags[row][col] = prevTag\n",
    "                        viterbiMatrix[row][col] = probabilityVal\n",
    "                        \n",
    "\n",
    "    #print viterbiMatrix\n",
    "    #print \"Last word: \",words[len(words) - 1]\n",
    "    finalStateVal = 0.0\n",
    "    finalTag = \"\"\n",
    "    for rowIndex in range(len(uniqueTags)):\n",
    "        tag = tagIndexDictReverse[rowIndex]\n",
    "        #print tag\n",
    "        finalStateProbability = endProbablities[tag] * viterbiMatrix[rowIndex][len(words) - 1]\n",
    "        #print endProbablities[tag]\n",
    "        #print finalStateProbability\n",
    "        #print viterbiMatrix[rowIndex][len(words) - 1]\n",
    "        if finalStateProbability > finalStateVal:\n",
    "            finalTag = tag\n",
    "            finalStateVal = finalStateProbability\n",
    "\n",
    "    assignedTags = [finalTag]\n",
    "\n",
    "    \n",
    "    currentTag = finalTag\n",
    "    #print finalTag\n",
    "    for colIndex in range(len(words)-1,0,-1):\n",
    "        #print currentTag\n",
    "        try:\n",
    "            currentTag = correspondingTags[tagIndexDict[currentTag]][colIndex]\n",
    "        except KeyError as e:\n",
    "            print viterbiMatrix[:,[len(words)-1]]\n",
    "            print \"--------------------------------\"\n",
    "            print emissionMatrix[:,[len(words)-1]]\n",
    "        assignedTags.append(currentTag)\n",
    "\n",
    "    assignedTags = assignedTags[::-1]\n",
    "#     print assignedTags\n",
    "#     print \"--------\"\n",
    "\n",
    "    predictedWordTagPair = []\n",
    "    for i in range(len(words)):\n",
    "        predictedWordTagPair.append('/'.join([words[i], assignedTags[i]]))\n",
    "    #print predictedWordTagPair\n",
    "    \n",
    "    taggedSentence = taggedTestData[sentenceIndex]\n",
    "    taggedWordTagPair = taggedSentence.strip(\"\\n\").split(\" \")\n",
    "    \n",
    "#     print \"Tagged: \"\n",
    "#     print taggedWordTagPair\n",
    "    \n",
    "#     totalWordCount += len(predictedWordTagPair)\n",
    "    \n",
    "    for index in range(len(predictedWordTagPair)):\n",
    "        totalWordCount += 1\n",
    "        if totalWordCount % 100 == 0:\n",
    "                print \"Accuracy: \", (correctlyTagged * 100.00 / totalWordCount)\n",
    "            \n",
    "        if predictedWordTagPair[index] == taggedWordTagPair[index]:\n",
    "            correctlyTagged += 1\n",
    "            \n",
    "    \n",
    "    #print correctlyTagged\n",
    "    # print correspondingTags\n",
    "    # print \"total: \", len(words) * len(uniqueTags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hiller/NNP asked/VBD Bush/NNP to/TO name/VB the/DT leaders/NNS of/IN Chechnya/NNP ,/, Taiwan/NNP ,/, India/NNP and/CC Pakistan/NNP ./.\n",
    "\"\n",
    "\n",
    "\"President/NNP Bush/NNP on/IN Tuesday/NNP nominated/VBD two/CD individuals/NNS to/TO replace/VB retiring/VBG jurists/NNS on/IN federal/JJ courts/NNS in/IN the/DT Washington/NNP area/NN ./.\"\n",
    "\"The/DT sheikh/NN in/IN wheel/NN -/HYPH chair/NN has/VBZ been/VBN attacked/VBN with/IN a/DT F/NN -/HYPH 16/CD -/HYPH launched/VBN bomb/NN ./.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correctlyTagged / totalWordCount\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.zeros(shape=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[1][1] = 87\n",
    "arr[1][3] = 21\n",
    "arr[3][1] = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
